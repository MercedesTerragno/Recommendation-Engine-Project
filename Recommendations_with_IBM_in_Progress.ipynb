{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recomm so far.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnoKPO42TNlp"
      },
      "source": [
        "# Recommendations with IBM in progress\n",
        "\n",
        "In this project we will analyze the interactions that users have with different articles on the **IBM Watson Studio platform**. We will study data available in that platform to build a recommendation engine that is able to show the articles that are most pertinent to each user.\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
        "II. [Rank Based Recommendations](#Rank)<br>\n",
        "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
        "IV. [Content Based Recommendations](#Content-Recs)<br>\n",
        "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
        "VI. [Extras & Concluding](#conclusions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AqhgCtvtTNl7",
        "outputId": "fdaad415-25a5-41e2-f9ce-133caa1f984d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import project_tests as t\n",
        "import pickle\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv('data/user-item-interactions.csv')\n",
        "df_content = pd.read_csv('data/articles_community.csv')\n",
        "del df['Unnamed: 0']\n",
        "del df_content['Unnamed: 0']\n",
        "\n",
        "# Show df to get an idea of the data\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>title</th>\n",
              "      <th>email</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1430.0</td>\n",
              "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
              "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1314.0</td>\n",
              "      <td>healthcare python streaming application demo</td>\n",
              "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1429.0</td>\n",
              "      <td>use deep learning for image classification</td>\n",
              "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1338.0</td>\n",
              "      <td>ml optimization using cognitive assistant</td>\n",
              "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1276.0</td>\n",
              "      <td>deploy your python model as a restful api</td>\n",
              "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_id                                              title  \\\n",
              "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
              "1      1314.0       healthcare python streaming application demo   \n",
              "2      1429.0         use deep learning for image classification   \n",
              "3      1338.0          ml optimization using cognitive assistant   \n",
              "4      1276.0          deploy your python model as a restful api   \n",
              "\n",
              "                                      email  \n",
              "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
              "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
              "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
              "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
              "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR7qhekfTNmJ",
        "outputId": "81b6af53-5514-4950-c589-ec525b88bd2e"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45993, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAk4B_l3TNmO"
      },
      "source": [
        "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrkhwNtrTNmo"
      },
      "source": [
        "**Removing duplicate articles** from the df_content dataframe: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C_Hla3uTNmw"
      },
      "source": [
        "df_content.article_id.value_counts();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSlnxxjBTNmz",
        "outputId": "7e3f9b44-8b5e-480e-b3b2-3dc37f18e7a1"
      },
      "source": [
        "df_content[df_content.article_id.isin([221, 232, 577, 398])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_body</th>\n",
              "      <th>doc_description</th>\n",
              "      <th>doc_full_name</th>\n",
              "      <th>doc_status</th>\n",
              "      <th>article_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>* United States\\r\\n\\r\\nIBM® * Site map\\r\\n\\r\\n...</td>\n",
              "      <td>When used to make sense of huge amounts of con...</td>\n",
              "      <td>How smart catalogs can turn the big data flood...</td>\n",
              "      <td>Live</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>Homepage Follow Sign in Get started Homepage *...</td>\n",
              "      <td>If you are like most data scientists, you are ...</td>\n",
              "      <td>Self-service data preparation with IBM Data Re...</td>\n",
              "      <td>Live</td>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>Homepage Follow Sign in Get started * Home\\r\\n...</td>\n",
              "      <td>Today’s world of data science leverages data f...</td>\n",
              "      <td>Using Apache Spark as a parallel processing fr...</td>\n",
              "      <td>Live</td>\n",
              "      <td>398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>This video shows you how to construct queries ...</td>\n",
              "      <td>This video shows you how to construct queries ...</td>\n",
              "      <td>Use the Primary Index</td>\n",
              "      <td>Live</td>\n",
              "      <td>577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
              "      <td>One of the earliest documented catalogs was co...</td>\n",
              "      <td>How smart catalogs can turn the big data flood...</td>\n",
              "      <td>Live</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>Homepage Follow Sign in Get started Homepage *...</td>\n",
              "      <td>Today’s world of data science leverages data f...</td>\n",
              "      <td>Using Apache Spark as a parallel processing fr...</td>\n",
              "      <td>Live</td>\n",
              "      <td>398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>This video shows you how to construct queries ...</td>\n",
              "      <td>This video shows you how to construct queries ...</td>\n",
              "      <td>Use the Primary Index</td>\n",
              "      <td>Live</td>\n",
              "      <td>577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>Homepage Follow Sign in Get started * Home\\r\\n...</td>\n",
              "      <td>If you are like most data scientists, you are ...</td>\n",
              "      <td>Self-service data preparation with IBM Data Re...</td>\n",
              "      <td>Live</td>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              doc_body  \\\n",
              "221  * United States\\r\\n\\r\\nIBM® * Site map\\r\\n\\r\\n...   \n",
              "232  Homepage Follow Sign in Get started Homepage *...   \n",
              "399  Homepage Follow Sign in Get started * Home\\r\\n...   \n",
              "578  This video shows you how to construct queries ...   \n",
              "692  Homepage Follow Sign in / Sign up Homepage * H...   \n",
              "761  Homepage Follow Sign in Get started Homepage *...   \n",
              "970  This video shows you how to construct queries ...   \n",
              "971  Homepage Follow Sign in Get started * Home\\r\\n...   \n",
              "\n",
              "                                       doc_description  \\\n",
              "221  When used to make sense of huge amounts of con...   \n",
              "232  If you are like most data scientists, you are ...   \n",
              "399  Today’s world of data science leverages data f...   \n",
              "578  This video shows you how to construct queries ...   \n",
              "692  One of the earliest documented catalogs was co...   \n",
              "761  Today’s world of data science leverages data f...   \n",
              "970  This video shows you how to construct queries ...   \n",
              "971  If you are like most data scientists, you are ...   \n",
              "\n",
              "                                         doc_full_name doc_status  article_id  \n",
              "221  How smart catalogs can turn the big data flood...       Live         221  \n",
              "232  Self-service data preparation with IBM Data Re...       Live         232  \n",
              "399  Using Apache Spark as a parallel processing fr...       Live         398  \n",
              "578                              Use the Primary Index       Live         577  \n",
              "692  How smart catalogs can turn the big data flood...       Live         221  \n",
              "761  Using Apache Spark as a parallel processing fr...       Live         398  \n",
              "970                              Use the Primary Index       Live         577  \n",
              "971  Self-service data preparation with IBM Data Re...       Live         232  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpsy5nNATNm4"
      },
      "source": [
        "df_content = df_content.drop_duplicates(subset= 'article_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7L1z27_gvV0"
      },
      "source": [
        "**Understanding the data:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvJWCBxRmpyC"
      },
      "source": [
        "- df: interaction between users and articles\n",
        "- df_content: information about each article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh70LKvlma_t"
      },
      "source": [
        "# distribution of how many articles a user interacts with in the dataset:\n",
        "\n",
        "user_articles_count = df.email.value_counts()\n",
        "user_articles_count.hist(range= [0,150]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuQbIcDRmjZS"
      },
      "source": [
        "# statistics\n",
        "user_articles_count.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg_mnWn0mnuM"
      },
      "source": [
        "print(\"The mean number of interactions per user is\", user_articles_count.mean(),\n",
        "      \"50% of individuals have\", user_articles_count.median(), \"or fewer interactions\",\n",
        "      \"The maximum number of user-article interactions by any 1 user is\", user_articles_count.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A88CIHQmmW85"
      },
      "source": [
        "# most viewed article: '1429.0', how often: 937 times \n",
        "df.article_id.value_counts();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr3P3vZVTNm8"
      },
      "source": [
        "unique_articles = df.article_id.nunique() # Number of unique articles that have at least one interaction\n",
        "total_articles = df_content.article_id.nunique() # Number of unique articles on the IBM platform\n",
        "unique_users = df.email.nunique() # Number of unique users\n",
        "user_article_interactions = df.shape[0] # Number of user-article interactions\n",
        "\n",
        "\n",
        "print(\"Unique articles with at least one interaction:\", unique_articles,\n",
        "      \"Total number of unique articles:\", total_articles,\n",
        "      \"Number of unique users:\", unique_users,\n",
        "      \"Number of user-article interactions\": user_article_interactions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4w3g1w7TNm_"
      },
      "source": [
        "**Email mapper**:\n",
        "\n",
        "The `email_mapper` function is used to map users' emails to ids.  There were a small number of null values, which likely belonged to a single user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz-izbQ1TNnE",
        "outputId": "a281e7c1-af7f-4258-a66c-04461dfccbfe"
      },
      "source": [
        "def email_mapper():\n",
        "  \"\"\" Function to map users' emails to user_id column \"\"\"\n",
        "    coded_dict = dict()\n",
        "    cter = 1\n",
        "    email_encoded = []\n",
        "    \n",
        "    for val in df['email']:\n",
        "        if val not in coded_dict:\n",
        "            coded_dict[val] = cter\n",
        "            cter+=1\n",
        "        \n",
        "        email_encoded.append(coded_dict[val])\n",
        "    return email_encoded\n",
        "\n",
        "email_encoded = email_mapper()\n",
        "\n",
        "# removing email column\n",
        "del df['email']\n",
        "df['user_id'] = email_encoded\n",
        "\n",
        "# show header\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>title</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1430.0</td>\n",
              "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1314.0</td>\n",
              "      <td>healthcare python streaming application demo</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1429.0</td>\n",
              "      <td>use deep learning for image classification</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1338.0</td>\n",
              "      <td>ml optimization using cognitive assistant</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1276.0</td>\n",
              "      <td>deploy your python model as a restful api</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_id                                              title  user_id\n",
              "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
              "1      1314.0       healthcare python streaming application demo        2\n",
              "2      1429.0         use deep learning for image classification        3\n",
              "3      1338.0          ml optimization using cognitive assistant        4\n",
              "4      1276.0          deploy your python model as a restful api        5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysukXOhKTNnk"
      },
      "source": [
        "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
        "\n",
        "We only know if a user has interacted with an article or not, but we don't have ratings to know if they liked them or not. In these cases, the popularity of an article can really only be based on how often an article was interacted with. \n",
        "\n",
        "Therefore, to make recommendations based on ranking, we will create a function that gives us the **top n article titles** from the df based on the number of interactions users had with them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU_5rN2QTNnm"
      },
      "source": [
        "def get_top_articles(n, df=df):\n",
        "    \"\"\"\n",
        "    Returns top n article titles from df, based on number of interactions.\n",
        "\n",
        "    INPUT:\n",
        "    n - (int) the number of top articles to return\n",
        "    df - (pandas dataframe) df as defined at the top of the notebook \n",
        "    \n",
        "    OUTPUT:\n",
        "    top_articles - (list) A list of the top 'n' article titles.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    ordered_titles = df.groupby(['title'])['user_id'].count().reset_index(\n",
        "  name='Count').sort_values(['Count'], ascending=False).title.values.tolist()\n",
        "    \n",
        "    top_articles = ordered_titles[:n]\n",
        "    \n",
        "    return top_articles # Return the top article titles from df (not df_content)\n",
        "\n",
        "\n",
        "def get_top_article_ids(n, df=df):\n",
        "    \"\"\"\n",
        "    Returns top n article ids from df, based on number of interactions.\n",
        "\n",
        "    INPUT:\n",
        "    n - (int) the number of top articles to return\n",
        "    df - (pandas dataframe) df as defined at the top of the notebook \n",
        "    \n",
        "    OUTPUT:\n",
        "    top_articles - (list) A list of the top 'n' article titles \n",
        "    \n",
        "    \"\"\"\n",
        "    ordered_ids = df.groupby(['article_id'])['user_id'].count().reset_index(\n",
        "        name='Count').sort_values(['Count'], ascending=False).article_id.values.tolist()\n",
        "    \n",
        "    top_articles = ordered_ids[:n]\n",
        " \n",
        "    return top_articles # Return the top article ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oualKRE3TNnp",
        "outputId": "ea643a0a-98cb-47e4-ccb7-c91548abc468"
      },
      "source": [
        "print(get_top_articles(10))\n",
        "print(get_top_article_ids(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['use deep learning for image classification', 'insights from new york car accident reports', 'visualize car data with brunel', 'use xgboost, scikit-learn & ibm watson machine learning apis', 'predicting churn with the spss random tree algorithm', 'healthcare python streaming application demo', 'finding optimal locations of new store using decision optimization', 'apache spark lab, part 1: basic concepts', 'analyze energy consumption in buildings', 'gosales transactions for logistic regression model']\n",
            "[1429.0, 1330.0, 1431.0, 1427.0, 1364.0, 1314.0, 1293.0, 1170.0, 1162.0, 1304.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxm_WYwq15np"
      },
      "source": [
        "def get_article_names(article_ids, df=df):\n",
        "    \"\"\" Return the article names associated with list of article ids.\n",
        "    \n",
        "    INPUT: \n",
        "    article_ids - (list) a list of article ids\n",
        "    df - (pandas dataframe) df as defined at the top of the notebook\n",
        "    \n",
        "    OUTPUT:\n",
        "    article_names - (list) a list of article names associated with the list of article ids \n",
        "                    (this is identified by the title column) \"\"\"\n",
        "\n",
        "    \n",
        "    article_names = list(set(df[df.article_id.isin(article_ids)].title.values))\n",
        "    \n",
        "    return article_names # Return the article names associated with list of article ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lhFZ1_ATNnu"
      },
      "source": [
        "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
        "\n",
        "In order to build better recommendations for the users of the IBM's platform, we will make recommendations to a user **based on the articles read by other users that are similar to them**, in terms of the items they have interacted with. This is called User-User collaborative filtering. \n",
        "\n",
        "\n",
        "For this purpose, we will:\n",
        "- build a **user by article matrix**, where there's a 1 if there was a interaction and a 0 otherwise. This will be useful to compute similarity between users, and also to retrieve which articles were seen by a given user. Therefore, using this matrix we will:\n",
        "    - build a function that retrieves the **articles a user has interacted with**.\n",
        "    - build a function that finds **most similar users** to any given user_id. Because the row for each user in our matrix is binary, we will compute similarity as the dot product between two users. When given a user_id, the function will return a pandas dataframe with all the neighbors sorted by similarity first, and number of interactions secondly.\n",
        "\n",
        "\n",
        "- build a function to **recommend articles** for any user_id, based on its similarity with other users and the articles they have interacted with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCz5N5f62vdf"
      },
      "source": [
        "**User by article matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yo8qC2UTNnv"
      },
      "source": [
        "def create_user_item_matrix(df):\n",
        "  \"\"\" Returns a user by article matrix, where there's a 1 if there was\n",
        "      an interaction and a 0 otherwise.\n",
        "    \n",
        "      INPUT: df - pandas dataframe with article_id, title, user_id columns\n",
        "      OUTPUT: user_item - (pandas dataframe) user by article matrix. \"\"\"\n",
        "    \n",
        "    df['ones'] = 1\n",
        "    user_item = df.groupby(['user_id', 'article_id'])['ones'].max().unstack()\n",
        "    user_item = user_item.replace(np.nan, 0)\n",
        "    \n",
        "    return user_item # return the user_item matrix \n",
        "\n",
        "user_item = create_user_item_matrix(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWhRZEa7vlBD"
      },
      "source": [
        "user_item.shape # 5149, 714"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Jq5EHh44M0"
      },
      "source": [
        "**Articles that a user_id has interacted with**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k65GjCVr43mU"
      },
      "source": [
        "def get_user_articles(user_id, user_item= user_item):\n",
        "    \"\"\" \n",
        "    Returns a list of the article_ids and article titles \n",
        "    that have been seen by a user.\n",
        "    \n",
        "    INPUT:\n",
        "    user_id - (int) a user id\n",
        "    user_item - (pandas dataframe) matrix of users by articles.\n",
        "    \n",
        "    OUTPUT:\n",
        "    article_ids - (list) a list of the article ids seen by the user\n",
        "    article_names - (list) a list of article names seen by the user\n",
        "    \"\"\"\n",
        "    \n",
        "    article_ids = user_item.columns[user_item.loc[user_id, :] == 1.0].tolist()\n",
        "    article_names = get_article_names(article_ids, df=df)\n",
        "    \n",
        "    # convert ids to strings\n",
        "    article_ids = [str(a) for a in article_ids]\n",
        "    \n",
        "    return article_ids, article_names # return the ids and names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rirgH4-uTNnz"
      },
      "source": [
        "**Most similar users**. \n",
        "\n",
        "**A few considerations:**\n",
        "* When choosing between users that have the same closeness to a given user, instead of doing it arbitrarily, we will choose those with the highest number of interactions. For that we will build the **get_top_sorted_users** function, which returns a dataframe with neighbors ordered by similarity first, and number of interactions secondly.\n",
        "\n",
        "* When, for a similar user, we get a number of recommendations that exceeds the number we need, instead of choosing the remaining articles arbitrarily, we will choose those with the highest number of total interactions first. This ranking can be obtained with the **top_articles** function we wrote before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC9Y9hWDehCR"
      },
      "source": [
        "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
        "    \"\"\" Returns a dataframe with all the neighbors of user_id, ordered first by\n",
        "    similarity and second by num_interactions, both in descending order.\n",
        "\n",
        "    INPUT:\n",
        "    user_id - (int)\n",
        "    df - (pandas dataframe) df as defined at the top of the notebook \n",
        "    user_item - (pandas dataframe) matrix of users by articles: \n",
        "                1's when a user has interacted with an article, 0 otherwise\n",
        "    \n",
        "    OUTPUT:\n",
        "    neighbors_df - (pandas dataframe) a dataframe with:\n",
        "                    neighbor_id - user_id of each neighbor.\n",
        "                    similarity - measure of the similarity of each neighbor to \n",
        "                                 input user_id\n",
        "                    num_interactions - number of articles seen by each neighbor\n",
        "    \"\"\"\n",
        "\n",
        "    user_idx = user_id - 1\n",
        "    \n",
        "    # neighbors\n",
        "    neighbor_ids = np.delete(np.array(user_item.index), user_idx) # without user itself\n",
        "    \n",
        "    # number of interactions per neighbor\n",
        "    n_interactions = [df[df.user_id == u].shape[0] for u in neighbor_ids] \n",
        "    \n",
        "    # similarities\n",
        "    user_item_np = np.array(user_item)\n",
        "    \n",
        "    similarity_vector = np.dot(user_item_np[user_idx, :], np.transpose(user_item_np))\n",
        "    similarity_vector = np.delete(similarity_vector, user_idx) # without user itself\n",
        "    \n",
        "    # dataframe\n",
        "    neighbors_df = pd.DataFrame({'neighbor_id': neighbor_ids,\n",
        "                                 'similarity' : similarity_vector,\n",
        "                                 'num_interactions' : n_interactions\n",
        "                                }).set_index('neighbor_id')\n",
        "    \n",
        "    # ordered by similarity and num_interactions\n",
        "    neighbors_df = neighbors_df.sort_values(by=['similarity', 'num_interactions'], \n",
        "                                            ascending=False)\n",
        "    \n",
        "    return neighbors_df # Return the dataframe specified in the doc_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_1SakHSZMW1"
      },
      "source": [
        "**Articles to recommend** based on User-User collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1On4R-LTNoN"
      },
      "source": [
        "def user_user_recs(user_id, m=10):\n",
        "    \"\"\"\n",
        "    Returns m recommendations for user_id based on collaborative filtering.\n",
        "\n",
        "    INPUT:\n",
        "    user_id - (int) a user id\n",
        "    m - (int) the number of recommendations you want for the user\n",
        "    \n",
        "    OUTPUT:\n",
        "    recs - (list) a list of m recommendations for the user by article id\n",
        "    rec_names - (list) a list of m recommendations for the user by article title\n",
        "    \n",
        "    Description:\n",
        "    Loops through the most similar users to the input user_id. \n",
        "    For each similar user, finds articles the input user hasn't seen before and\n",
        "    provides them as recs. This is done this until m recommendations are found.\n",
        "    \n",
        "    Notes:\n",
        "    - Similar users who are the same closeness to input user are chosen based on\n",
        "    the number of total interactions they had. The one with most interactions is\n",
        "    chosen.\n",
        "\n",
        "    - When, for a similar user, we get a number of recommendations that exceeds \n",
        "    m, the articles to reach m are chosen based on the total number of \n",
        "    interactions the articles had. Those with more interactions are chosen first.\n",
        "    If same number of interactions is found, it's chosen arbitrarily. \n",
        "    \"\"\"\n",
        "    \n",
        "    recs = np.array([])\n",
        "    \n",
        "    seen_articles, _ = get_user_articles(user_id)\n",
        "    \n",
        "    neighbors_df = get_top_sorted_users(user_id)\n",
        "    \n",
        "    for nb in neighbors_df.index:\n",
        "        potential_articles, _ = get_user_articles(nb)\n",
        "\n",
        "        potential_recs = [a for a in potential_articles if a not in seen_articles]\n",
        "        \n",
        "        total_so_far = len(recs) + len(potential_recs)\n",
        "        if total_so_far <= m:\n",
        "            \n",
        "            # agregar todos los articulos de ese nb\n",
        "            recs = np.append(recs, potential_recs)\n",
        "            \n",
        "            if total_so_far == m: break\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            # if i'm passing m, choose needed number of articles with more interactions and break\n",
        "            n_final = m - total_so_far\n",
        "            \n",
        "            # first we need integers\n",
        "            potential_recs = [int(float(pr)) for pr in potential_recs]\n",
        "            \n",
        "            # get all articles ordered by number of interactions\n",
        "            total_n_articles = df.article_id.nunique()\n",
        "            top_articles = get_top_article_ids(total_n_articles, df=df)\n",
        "            \n",
        "            # dict mapping ids in potential_recs with index in top_articles\n",
        "            # lower number is higher in ranking\n",
        "            ids_order = {}\n",
        "            for pr in potential_recs:    \n",
        "                ids_order[pr] = np.where(np.array(top_articles) == pr)[0][0]\n",
        "            \n",
        "            # ordered list\n",
        "            recs_ordered = list(dict(sorted(ids_order.items(), \n",
        "                                            key=lambda item: item[1])).keys())\n",
        "            \n",
        "            # get the number needed\n",
        "            new_recs = recs_ordered[:n_final]\n",
        "            recs = np.append(recs, new_recs)\n",
        "            \n",
        "            break\n",
        "        \n",
        "\n",
        "        \n",
        "    rec_names = get_article_names(recs)\n",
        "    recs_str = [str(r) for r in recs]\n",
        "    \n",
        "    return recs_str, rec_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbDPvRyVgzFd",
        "outputId": "1384dbb4-aeca-4264-eade-e9b4738dc35b"
      },
      "source": [
        "# Quick spot check - don't change this code - just use it to test your functions\n",
        "rec_ids, rec_names = user_user_recs(20, 10)\n",
        "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
        "print(rec_ids)\n",
        "print()\n",
        "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
        "print(rec_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The top 10 recommendations for user 20 are the following article ids:\n",
            "['1330.0', '1427.0', '1364.0', '1170.0', '1162.0', '1304.0', '1351.0', '1160.0', '1354.0', '1368.0']\n",
            "\n",
            "The top 10 recommendations for user 20 are the following article names:\n",
            "['use xgboost, scikit-learn & ibm watson machine learning apis', 'putting a human face on machine learning', 'gosales transactions for logistic regression model', 'model bike sharing data with spss', 'analyze accident reports on amazon emr spark', 'movie recommender system with spark machine learning', 'apache spark lab, part 1: basic concepts', 'insights from new york car accident reports', 'predicting churn with the spss random tree algorithm', 'analyze energy consumption in buildings']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}